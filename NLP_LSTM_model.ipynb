{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Data\n",
    "Dataset here will be the Babi Data Set from Facebook Research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('train_qa.txt','rb') as f:\n",
    "    train_data=pickle.load(f)\n",
    "    \n",
    "with open('test_qa.txt','rb') as f:\n",
    "    test_data=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of test data 1000\n",
      "length of train data 10000\n",
      "type of data <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(\"length of test data\",len(test_data))\n",
    "print(\"length of train data\",len(train_data))\n",
    "print(\"type of data\",type(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring how the data looks\n",
    "train_data[0]\n",
    "# train_data[0][0] is story and train_data[0][1] is question and train_data[0][2] is answer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story-> Mary moved to the bathroom . Sandra journeyed to the bedroom . question-> Is Sandra in the hallway ? answer : n o\n"
     ]
    }
   ],
   "source": [
    "print(\"story->\",' '.join(train_data[0][0]),\"question->\",' '.join(train_data[0][1]),\"answer :\",' '.join(train_data[0][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    }
   ],
   "source": [
    "#combining the data\n",
    "all_data=test_data+ train_data\n",
    "print(len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding vocabulary in the set\n",
    "vocab =set()\n",
    "for story,question,answer in all_data:\n",
    "    vocab=vocab.union(set(story))\n",
    "    vocab=vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview of vocab\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len=len(vocab)+1#we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Longest story\n",
    "\n",
    "all_story_lens=[len(data[0]) for data in all_data]\n",
    "maximum_story_len=max(all_story_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Longest question\n",
    "all_question_lens=[len(data[1]) for data in all_data]\n",
    "maximum_question_len=max(all_question_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer=Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 1,\n",
       " 'daniel': 2,\n",
       " 'journeyed': 3,\n",
       " 'grabbed': 4,\n",
       " 'moved': 5,\n",
       " 'got': 6,\n",
       " 'milk': 7,\n",
       " 'to': 8,\n",
       " 'no': 9,\n",
       " 'kitchen': 10,\n",
       " 'is': 11,\n",
       " 'the': 12,\n",
       " 'bathroom': 13,\n",
       " 'office': 14,\n",
       " 'back': 15,\n",
       " 'yes': 16,\n",
       " 'there': 17,\n",
       " 'football': 18,\n",
       " 'up': 19,\n",
       " 'sandra': 20,\n",
       " 'left': 21,\n",
       " 'dropped': 22,\n",
       " 'hallway': 23,\n",
       " 'john': 24,\n",
       " '?': 25,\n",
       " 'bedroom': 26,\n",
       " 'in': 27,\n",
       " 'went': 28,\n",
       " 'took': 29,\n",
       " 'put': 30,\n",
       " 'discarded': 31,\n",
       " 'garden': 32,\n",
       " 'picked': 33,\n",
       " 'travelled': 34,\n",
       " 'down': 35,\n",
       " '.': 36,\n",
       " 'mary': 37}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text=[]\n",
    "train_question_text=[]\n",
    "train_answers=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into 3 seperate lists\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq =tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n    OUTPUT:\\n    \\n    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\\n    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\\n    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\\n    \\n    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize_stories(data,word_index=tokenizer.word_index,max_story_len=maximum_story_len,max_question_len=maximum_question_len):\n",
    "    #Stories=X\n",
    "    X=[]\n",
    "    #Questions=Xq\n",
    "    Xq=[]\n",
    "    #Y Correct answer(yes/no)\n",
    "    Y=[]\n",
    "    \n",
    "    for story,query,answer in data:\n",
    "        x=[word_index[word.lower()] for word  in story]\n",
    "        xq=[word_index[word.lower()] for word in query]\n",
    "        y=np.zeros(len(word_index)+1)\n",
    "        y[word_index[answer]]=1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return (pad_sequences(X,maxlen=maximum_story_len),pad_sequences(Xq,maxlen=maximum_question_len),np.array(Y))\n",
    "'''\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train , queries_train , answers_train =vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test , queries_test , answers_test =vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 12, 26, 36],\n",
       "       [ 0,  0,  0, ..., 12, 32, 36],\n",
       "       [ 0,  0,  0, ..., 12, 32, 36],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 12,  1, 36],\n",
       "       [ 0,  0,  0, ..., 12, 32, 36],\n",
       "       [ 0,  0,  0, ...,  1, 17, 36]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of vectorized data\n",
    "inputs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have two inputs stories and questions\n",
    "input_sequence=Input((maximum_story_len,))\n",
    "question=Input((maximum_question_len,))\n",
    "#Input() is used to instantiate a Keras tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build this network we have choosen the below article\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT ENCODER M\n",
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m=Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT ENCODER C\n",
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c=Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=maximum_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question ENCODER C\n",
    "# embed the question into a sequence of vectors\n",
    "question_encoder=Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,output_dim=64,input_length=maximum_question_len))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoded<---encoder(input)\n",
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m =input_encoder_m(input_sequence)\n",
    "input_encoded_c =input_encoder_c(input_sequence)\n",
    "question_encoded=question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer=concatenate([response,question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer=LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, None, 64)     2432        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 156, 6)       0           sequential[0][0]                 \n",
      "                                                                 sequential_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, None, 6)      228         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
      "                                                                 sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
      "                                                                 sequential_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 6s 11ms/step - loss: 0.9066 - accuracy: 0.4871 - val_loss: 0.6979 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.7041 - accuracy: 0.4938 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6970 - accuracy: 0.4880 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6938 - accuracy: 0.5101 - val_loss: 0.6987 - val_accuracy: 0.4970\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6953 - accuracy: 0.4969 - val_loss: 0.6941 - val_accuracy: 0.5030\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6943 - accuracy: 0.5025 - val_loss: 0.6945 - val_accuracy: 0.5030\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.6949 - accuracy: 0.4907 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6942 - accuracy: 0.5035 - val_loss: 0.6959 - val_accuracy: 0.4970\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6934 - accuracy: 0.5077 - val_loss: 0.6946 - val_accuracy: 0.5010\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6861 - accuracy: 0.5426 - val_loss: 0.6835 - val_accuracy: 0.5390\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6613 - accuracy: 0.5992 - val_loss: 0.6480 - val_accuracy: 0.6560\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6457 - accuracy: 0.6316 - val_loss: 0.6356 - val_accuracy: 0.6600\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.6369 - accuracy: 0.6440 - val_loss: 0.6299 - val_accuracy: 0.6590\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.6273 - accuracy: 0.6579 - val_loss: 0.6237 - val_accuracy: 0.6560\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6208 - accuracy: 0.6642 - val_loss: 0.6224 - val_accuracy: 0.6580\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6129 - accuracy: 0.6727 - val_loss: 0.6077 - val_accuracy: 0.6680\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6056 - accuracy: 0.6826 - val_loss: 0.6079 - val_accuracy: 0.6670\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5934 - accuracy: 0.6930 - val_loss: 0.5929 - val_accuracy: 0.6730\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5870 - accuracy: 0.6939 - val_loss: 0.5815 - val_accuracy: 0.6830\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5737 - accuracy: 0.7030 - val_loss: 0.5931 - val_accuracy: 0.6800\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5625 - accuracy: 0.7133 - val_loss: 0.5708 - val_accuracy: 0.6860\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5491 - accuracy: 0.7205 - val_loss: 0.5531 - val_accuracy: 0.7120\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5346 - accuracy: 0.7294 - val_loss: 0.5369 - val_accuracy: 0.7240\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5170 - accuracy: 0.7446 - val_loss: 0.5217 - val_accuracy: 0.7330\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5006 - accuracy: 0.7546 - val_loss: 0.5214 - val_accuracy: 0.7400\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.4884 - accuracy: 0.7590 - val_loss: 0.4931 - val_accuracy: 0.7640\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.4812 - accuracy: 0.7709 - val_loss: 0.4926 - val_accuracy: 0.7570\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.4749 - accuracy: 0.7766 - val_loss: 0.4758 - val_accuracy: 0.7780\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.4641 - accuracy: 0.7821 - val_loss: 0.4813 - val_accuracy: 0.7850\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.4555 - accuracy: 0.7899 - val_loss: 0.4839 - val_accuracy: 0.7680\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.4463 - accuracy: 0.7963 - val_loss: 0.4683 - val_accuracy: 0.7760\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.4399 - accuracy: 0.8016 - val_loss: 0.4744 - val_accuracy: 0.7770\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.4348 - accuracy: 0.8003 - val_loss: 0.4643 - val_accuracy: 0.7970\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.4335 - accuracy: 0.7994 - val_loss: 0.4540 - val_accuracy: 0.7890\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.4260 - accuracy: 0.8080 - val_loss: 0.4735 - val_accuracy: 0.7850\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.4216 - accuracy: 0.8106 - val_loss: 0.4477 - val_accuracy: 0.7980\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.4228 - accuracy: 0.8066 - val_loss: 0.4590 - val_accuracy: 0.7890\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.4173 - accuracy: 0.8110 - val_loss: 0.4405 - val_accuracy: 0.7990\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.4102 - accuracy: 0.8123 - val_loss: 0.4657 - val_accuracy: 0.7910\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.4054 - accuracy: 0.8189 - val_loss: 0.4460 - val_accuracy: 0.7940\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.4081 - accuracy: 0.8135 - val_loss: 0.4629 - val_accuracy: 0.7930\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.4036 - accuracy: 0.8172 - val_loss: 0.4428 - val_accuracy: 0.8020\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3971 - accuracy: 0.8171 - val_loss: 0.4582 - val_accuracy: 0.7950\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3974 - accuracy: 0.8223 - val_loss: 0.4544 - val_accuracy: 0.8060\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3989 - accuracy: 0.8232 - val_loss: 0.4386 - val_accuracy: 0.8070\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.4035 - accuracy: 0.8162 - val_loss: 0.4604 - val_accuracy: 0.7920\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3907 - accuracy: 0.8213 - val_loss: 0.4698 - val_accuracy: 0.8030\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3887 - accuracy: 0.8275 - val_loss: 0.4628 - val_accuracy: 0.7950\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3856 - accuracy: 0.8247 - val_loss: 0.4430 - val_accuracy: 0.8030\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3869 - accuracy: 0.8237 - val_loss: 0.4553 - val_accuracy: 0.7990\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3844 - accuracy: 0.8257 - val_loss: 0.4634 - val_accuracy: 0.7930\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3871 - accuracy: 0.8244 - val_loss: 0.4479 - val_accuracy: 0.8010\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3832 - accuracy: 0.8273 - val_loss: 0.4577 - val_accuracy: 0.7850\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3816 - accuracy: 0.8236 - val_loss: 0.4676 - val_accuracy: 0.8000\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3807 - accuracy: 0.8262 - val_loss: 0.4547 - val_accuracy: 0.7840\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3841 - accuracy: 0.8259 - val_loss: 0.4546 - val_accuracy: 0.8020\n",
      "Epoch 57/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3752 - accuracy: 0.8306 - val_loss: 0.4449 - val_accuracy: 0.7980\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3729 - accuracy: 0.8295 - val_loss: 0.4733 - val_accuracy: 0.7890\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3750 - accuracy: 0.8298 - val_loss: 0.4645 - val_accuracy: 0.7970\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3749 - accuracy: 0.8314 - val_loss: 0.4575 - val_accuracy: 0.7990\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3741 - accuracy: 0.8296 - val_loss: 0.4602 - val_accuracy: 0.7960\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3666 - accuracy: 0.8368 - val_loss: 0.4676 - val_accuracy: 0.7960\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3699 - accuracy: 0.8310 - val_loss: 0.4580 - val_accuracy: 0.7990\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3659 - accuracy: 0.8319 - val_loss: 0.4756 - val_accuracy: 0.7970\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3687 - accuracy: 0.8323 - val_loss: 0.4663 - val_accuracy: 0.7960\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3656 - accuracy: 0.8362 - val_loss: 0.4673 - val_accuracy: 0.7910\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3670 - accuracy: 0.8381 - val_loss: 0.4921 - val_accuracy: 0.7910\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3664 - accuracy: 0.8311 - val_loss: 0.4773 - val_accuracy: 0.7910\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3587 - accuracy: 0.8397 - val_loss: 0.4977 - val_accuracy: 0.7960\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3578 - accuracy: 0.8392 - val_loss: 0.4779 - val_accuracy: 0.7940\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3520 - accuracy: 0.8433 - val_loss: 0.4881 - val_accuracy: 0.7950\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3533 - accuracy: 0.8411 - val_loss: 0.4939 - val_accuracy: 0.7790\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3508 - accuracy: 0.8399 - val_loss: 0.5119 - val_accuracy: 0.7860\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3543 - accuracy: 0.8401 - val_loss: 0.4938 - val_accuracy: 0.7980\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3469 - accuracy: 0.8420 - val_loss: 0.4868 - val_accuracy: 0.8020\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3434 - accuracy: 0.8472 - val_loss: 0.4875 - val_accuracy: 0.7960\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3494 - accuracy: 0.8452 - val_loss: 0.5284 - val_accuracy: 0.7950\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3467 - accuracy: 0.8459 - val_loss: 0.5150 - val_accuracy: 0.7950\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3484 - accuracy: 0.8440 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3425 - accuracy: 0.8501 - val_loss: 0.5091 - val_accuracy: 0.7950\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3433 - accuracy: 0.8477 - val_loss: 0.5376 - val_accuracy: 0.7930\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3405 - accuracy: 0.8477 - val_loss: 0.4967 - val_accuracy: 0.7990\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3339 - accuracy: 0.8526 - val_loss: 0.5380 - val_accuracy: 0.7960\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3358 - accuracy: 0.8496 - val_loss: 0.5075 - val_accuracy: 0.8020\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3387 - accuracy: 0.8476 - val_loss: 0.4750 - val_accuracy: 0.7920\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3377 - accuracy: 0.8477 - val_loss: 0.5149 - val_accuracy: 0.8010\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3346 - accuracy: 0.8533 - val_loss: 0.5331 - val_accuracy: 0.7970\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3358 - accuracy: 0.8466 - val_loss: 0.5143 - val_accuracy: 0.7870\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3331 - accuracy: 0.8517 - val_loss: 0.5319 - val_accuracy: 0.8000\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3295 - accuracy: 0.8541 - val_loss: 0.5219 - val_accuracy: 0.7940\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3284 - accuracy: 0.8524 - val_loss: 0.5185 - val_accuracy: 0.8030\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3315 - accuracy: 0.8563 - val_loss: 0.5330 - val_accuracy: 0.7970\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3211 - accuracy: 0.8573 - val_loss: 0.5164 - val_accuracy: 0.7940loss: 0.3212 - accuracy - ETA: 1s - loss: 0.3260 - ac - ETA: 1s - - ETA: 0s - loss: 0.3195 - ac\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3261 - accuracy: 0.8562 - val_loss: 0.5356 - val_accuracy: 0.7930\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3242 - accuracy: 0.8575 - val_loss: 0.5328 - val_accuracy: 0.7950\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3173 - accuracy: 0.8592 - val_loss: 0.5373 - val_accuracy: 0.7950\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3227 - accuracy: 0.8570 - val_loss: 0.5326 - val_accuracy: 0.7920\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3142 - accuracy: 0.8596 - val_loss: 0.5432 - val_accuracy: 0.7950\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3214 - accuracy: 0.8611 - val_loss: 0.5183 - val_accuracy: 0.7970\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3193 - accuracy: 0.8632 - val_loss: 0.5391 - val_accuracy: 0.7900\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3120 - accuracy: 0.8623 - val_loss: 0.5553 - val_accuracy: 0.7890\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3137 - accuracy: 0.8613 - val_loss: 0.5406 - val_accuracy: 0.7930\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3101 - accuracy: 0.8627 - val_loss: 0.5267 - val_accuracy: 0.7920\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3064 - accuracy: 0.8659 - val_loss: 0.5459 - val_accuracy: 0.7900\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3113 - accuracy: 0.8642 - val_loss: 0.5482 - val_accuracy: 0.7910\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3098 - accuracy: 0.8626 - val_loss: 0.5248 - val_accuracy: 0.7950\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3066 - accuracy: 0.8670 - val_loss: 0.5451 - val_accuracy: 0.7920\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3066 - accuracy: 0.8644 - val_loss: 0.5406 - val_accuracy: 0.7930\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3044 - accuracy: 0.8687 - val_loss: 0.5414 - val_accuracy: 0.7930\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2971 - accuracy: 0.8717 - val_loss: 0.5883 - val_accuracy: 0.7940\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3022 - accuracy: 0.8661 - val_loss: 0.5562 - val_accuracy: 0.7970\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2973 - accuracy: 0.8694 - val_loss: 0.5588 - val_accuracy: 0.7980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2975 - accuracy: 0.8689 - val_loss: 0.5493 - val_accuracy: 0.7920\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2986 - accuracy: 0.8708 - val_loss: 0.5686 - val_accuracy: 0.7960\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2998 - accuracy: 0.8660 - val_loss: 0.5773 - val_accuracy: 0.7990\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2947 - accuracy: 0.8724 - val_loss: 0.5572 - val_accuracy: 0.7950\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2943 - accuracy: 0.8692 - val_loss: 0.5499 - val_accuracy: 0.7980\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2914 - accuracy: 0.8754 - val_loss: 0.5377 - val_accuracy: 0.7950\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2922 - accuracy: 0.8714 - val_loss: 0.5329 - val_accuracy: 0.8020\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2931 - accuracy: 0.8728 - val_loss: 0.5459 - val_accuracy: 0.7950\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmegh\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "filename = 'chatbot_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n",
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)\n",
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9923131\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
